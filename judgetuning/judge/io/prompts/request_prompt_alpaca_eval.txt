I require a leaderboard for various large language models. I'll provide you with prompts given to these models and their corresponding responses. Your task is to assess these responses, ranking the models in order of preference from a human perspective. Once ranked, please output the results in a structured JSON format for the make_partial_leaderboard function.

## Prompt

{
    "prompt": {instruction}
}

## Model Outputs

Here are the unordered outputs from the models. Each output is associated with a specific model, identified by a unique model identifier.

{
    {
        "model": "m",
        "output": {output1}
    },
    {
        "model": "M",
        "output": {output2}
    }
}

## Task

Evaluate and rank the models based on the quality and relevance of their outputs. The ranking should be such that the model with the highest quality output is ranked first.

## Judgement

You must output EITHER "m" or "M". Do not provide an explanation.

Example of valid outputs are:
* Best model identifier: "m" (if you think that "m" is better)
* Best model identifier: "M" (if you think that "M" is better)

Best model identifier: